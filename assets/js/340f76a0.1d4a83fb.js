"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2216],{8453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>l});var t=n(6540);const i={},a=t.createContext(i);function o(e){const s=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(a.Provider,{value:s},e.children)}},9590:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>h,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>r});const t=JSON.parse('{"id":"Integrations/Bhashini Integrations","title":"Bhashini Integrations","description":"### 4 minute read &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Advanced","source":"@site/docs/5. Integrations/Bhashini Integrations.md","sourceDirName":"5. Integrations","slug":"/Integrations/Bhashini Integrations","permalink":"/docs/docs/Integrations/Bhashini Integrations","draft":false,"unlisted":false,"editUrl":"https://github.com/glific/docs/tree/main/docs/5. Integrations/Bhashini Integrations.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Integrations","permalink":"/docs/docs/category/integrations"},"next":{"title":"ChatGPT using OpenAI APIs","permalink":"/docs/docs/Integrations/ChatGPT using OpenAI APIs"}}');var i=n(4848),a=n(8453);const o={},l=void 0,h={},r=[{value:"<strong>4 minute read \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 <code>Advanced</code></strong>",id:"4-minute-read-------------------------------------------------------------advanced",level:3},{value:"Bhashini in Glific",id:"bhashini-in-glific",level:2},{value:"Steps to integrate Bhashini Speech To Text in Glific flows",id:"steps-to-integrate-bhashini-speech-to-text-in-glific-flows",level:2},{value:"Steps to integrate Bhashini Text To Speech in Glific flows",id:"steps-to-integrate-bhashini-text-to-speech-in-glific-flows",level:2},{value:"Sample Flow Links",id:"sample-flow-links",level:2},{value:"Blogs",id:"blogs",level:2}];function c(e){const s={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.h3,{id:"4-minute-read-------------------------------------------------------------advanced",children:(0,i.jsxs)(s.strong,{children:["4 minute read \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 ",(0,i.jsx)(s.code,{children:"Advanced"})]})}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsxs)(s.strong,{children:[(0,i.jsx)(s.code,{children:"Bhashini"})," is an initiative aimed at providing easy access to the Internet and digital services for all Indians in their native languages. The primary goal of the project is to increase the amount of content available in Indian languages, thereby promoting digital inclusivity and accessibility for a broader population"]})}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h2,{id:"bhashini-in-glific",children:"Bhashini in Glific"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Bhashini APIs are used in Glific for converting ",(0,i.jsx)(s.strong,{children:"speech to text"})," and ",(0,i.jsx)(s.strong,{children:"text to speech"})]}),"\n",(0,i.jsx)(s.li,{children:"By using speech to text, voice notes sent by users to chatbot can be converted into texts by NGOs"}),"\n",(0,i.jsx)(s.li,{children:"By using text to speech, text messages being sent via Glific platform to users can also be converted to voice notes in respective indic languages"}),"\n"]}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h2,{id:"steps-to-integrate-bhashini-speech-to-text-in-glific-flows",children:"Steps to integrate Bhashini Speech To Text in Glific flows"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["After the audio is captured, the Bhashini ASR API is called using a Webhook function called ",(0,i.jsx)(s.code,{children:"speech_to_text_with_bhasini"}),'. The response in the given example is stored as "bhashini_asr".']}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"The function name is pre-defined, you should always use the name \u2018speech_to_text_with_bhasini\u2019 to call the Bhashini API"}),"\n",(0,i.jsx)(s.li,{children:"The webhook result name could be given any name of your liking, just like any other flow variable"}),"\n"]}),"\n",(0,i.jsx)("img",{width:"1301",alt:"Screenshot 2024-06-27 at 3 59 52\u202fPM",src:"https://github.com/glific/docs/assets/141305477/7495a80a-7c27-400e-95c9-0a6ca866a903"}),"\n",(0,i.jsxs)(s.ol,{start:"7",children:["\n",(0,i.jsx)(s.li,{children:"The webhook body is shown below. Please update the parameters as shown :"}),"\n"]}),"\n",(0,i.jsx)("img",{width:"556",alt:"Screenshot 2024-06-27 at 4 00 41\u202fPM",src:"https://github.com/glific/docs/assets/141305477/5bdf92e6-dff4-47bc-8557-7fab17cd6384"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"speech : It should be updated with the result name given for the audio file captured. Here, it is saved as \u2018speech\u2019 (Step 5), hence the value is @results.speech.input (If the audio note captured was saved as \u2018query\u2019, then the value will be @results.query.input)"}),"\n",(0,i.jsx)(s.li,{children:"contact : Keep the value as given in the screenshot below - \u201c@contact\u201d"}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"8",children:["\n",(0,i.jsxs)(s.li,{children:["Once the webhook is updated, you could always refer to the translated text as ",(0,i.jsx)(s.code,{children:"@results.bhashini_asr.asr_response_text"})," to use it inside the flow."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"The output of the text response from the Bhashini depends on the language preference of the user. For instance if a user has selected Hindi language, the response from Glific will be in Hindi script."}),"\n",(0,i.jsx)(s.h2,{id:"steps-to-integrate-bhashini-text-to-speech-in-glific-flows",children:"Steps to integrate Bhashini Text To Speech in Glific flows"}),"\n",(0,i.jsx)("img",{width:"1075",alt:"Screenshot 2024-06-27 at 4 19 36\u202fPM",src:"https://github.com/glific/docs/assets/141305477/c4c5c951-8ec7-4278-8d3c-e27e6f2aaca2"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"This webhook can be used to generated a voice note for any given text message, it can be user generated or NGO staff written. (Above screen shot is of an example flow which takes in a user input text, and converts it inot a text message and voice note in a desired langauge)"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Call the webhook with function name as ",(0,i.jsx)(s.code,{children:"nmt_tts_with_bhasini"}),". Give an appropriate name to the webhook result. In the shown example the result name is ",(0,i.jsx)(s.code,{children:"bhashini_tts"})]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Go to function body and pass the following params\n",(0,i.jsx)(s.code,{children:'{ "text": "@results.result_3", "source_language": "english", "target_language": "hindi" }'}),"\nhere ",(0,i.jsx)(s.code,{children:"text"})," is the text to be converted into voice note\n",(0,i.jsx)(s.code,{children:"source_language"})," is the langauge of the text\n",(0,i.jsx)(s.code,{children:"target_language"})," is the language the voice notes need to be in"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Keep source language and target language same if translation is not needed."}),"\n",(0,i.jsxs)(s.li,{children:["Following are the possible values for ",(0,i.jsx)(s.code,{children:"target_language"})," as covered by Bhashini\n",(0,i.jsx)(s.code,{children:'"tamil"    "kannada"   "malayalam"   "telugu"    "assamese"   "gujarati"    "bengali"   "punjabi"    "marathi"    "urdu"    "spanish"    "english"   "hindi"'})]}),"\n"]}),"\n",(0,i.jsx)("img",{width:"568",alt:"Screenshot 2024-06-27 at 4 12 20\u202fPM",src:"https://github.com/glific/docs/assets/141305477/6718032f-84de-493c-bde2-d3e302c9a0f2"}),"\n",(0,i.jsxs)(s.ol,{start:"4",children:["\n",(0,i.jsxs)(s.li,{children:["To get the voice note output, create a send message node, go to attachments, select ",(0,i.jsx)(s.code,{children:"Expression"})," from the dropdown of attachment types. Pass the variable ",(0,i.jsx)(s.code,{children:"@results.bhasini_tts.media_url"}),". Here ",(0,i.jsx)(s.code,{children:"bhashini_tts"})," is the name for the webhook result."]}),"\n"]}),"\n",(0,i.jsx)("img",{width:"592",alt:"Screenshot 2024-06-27 at 4 20 30\u202fPM",src:"https://github.com/glific/docs/assets/141305477/975bab6d-6a41-4ef3-91a1-b611d74fbbab"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Please note"}),": In order to get the voice notes as outputs, the Glific instance must be linked to the Google Cloud Storage for your organization. This is to facilitate storage of the voice notes generated by Bhashini as a result of the webhook call. To set up Google Cloud Storage go ",(0,i.jsx)(s.a,{href:"https://glific.github.io/docs/docs/Onboarding/GCS%20Setup/Google%20Cloud%20Storage%20Setup",children:"here"})]}),"\n",(0,i.jsxs)(s.ol,{start:"5",children:["\n",(0,i.jsxs)(s.li,{children:["To get the translated text out, create another send message node, and call the ",(0,i.jsx)(s.code,{children:"@results.bhasini_tts.translated_text"}),". Here ",(0,i.jsx)(s.code,{children:"bhashini_tts"})," is the name for the webhook result."]}),"\n"]}),"\n",(0,i.jsx)("img",{width:"589",alt:"Screenshot 2024-06-27 at 4 25 50\u202fPM",src:"https://github.com/glific/docs/assets/141305477/56ea5b67-b164-4347-96ff-ba00c2d79d7c"}),"\n",(0,i.jsx)(s.h2,{id:"sample-flow-links",children:"Sample Flow Links"}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.em,{children:"Test some sample flows for yourself by importing these flows to your Glific instance."})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://drive.google.com/file/d/1qkNGzLCQacrlP96GCytCihRGM4LhfokL/view?usp=sharing",children:"Bhashini Speech to Text"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://drive.google.com/file/d/1WCOLQMF-OgLVR7PNHXbggMSeDXMJbui7/view?usp=drive_link",children:"Bhashini Text to Speech"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"blogs",children:"Blogs"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://glific.org/getting-started-using-asr-with-bhashini-api/",children:"Getting started with Bhashini ASR"})}),"\n"]})]})}function d(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);