"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8560],{9248:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var t=n(4848),i=n(8453);const o={},a=void 0,r={id:"Integrations/RAG using OpenAI file search assistant",title:"RAG using OpenAI file search assistant",description:"3 minute read &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Advanced",source:"@site/docs/4. Integrations/RAG using OpenAI file search assistant.md",sourceDirName:"4. Integrations",slug:"/Integrations/RAG using OpenAI file search assistant",permalink:"/docs/docs/Integrations/RAG using OpenAI file search assistant",draft:!1,unlisted:!1,editUrl:"https://github.com/glific/docs/tree/main/docs/4. Integrations/RAG using OpenAI file search assistant.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Google Maps API for reverse geo location",permalink:"/docs/docs/Integrations/Google Maps API for reverse geo location"},next:{title:"Setting up Exotel",permalink:"/docs/docs/Integrations/Setting up Exotel"}},c={},l=[{value:"How to create an OpenAI Assistant from Glific UI",id:"how-to-create-an-openai-assistant-from-glific-ui",level:2},{value:"Using the OpenAI assistant in floweditor",id:"using-the-openai-assistant-in-floweditor",level:2},{value:"Handling text inputs and outputs",id:"handling-text-inputs-and-outputs",level:3},{value:"Handling voice inputs and outputs responses",id:"handling-voice-inputs-and-outputs-responses",level:3},{value:"Pricing",id:"pricing",level:3},{value:"Limitations",id:"limitations",level:2},{value:"Video of showcase",id:"video-of-showcase",level:2}];function h(e){const s={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(s.p,{children:["###",(0,t.jsxs)(s.strong,{children:["3 minute read \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 ",(0,t.jsx)(s.code,{children:"Advanced"})]})]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.em,{children:(0,t.jsx)(s.strong,{children:"Provide your documents, and system prompt, get GPT model to answer questions of your users over WhatsApp from the provided documents, with the ability to handle the follow up questions asked by the users"})})}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.em,{children:"This is the implementation of RAG system provided by OpenAI in Glific"})}),"\n",(0,t.jsx)(s.h2,{id:"how-to-create-an-openai-assistant-from-glific-ui",children:"How to create an OpenAI Assistant from Glific UI"}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["Go to the ",(0,t.jsx)(s.code,{children:"Assistants"})," page from the left panel."]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"1409",alt:"Screenshot 2024-11-18 at 2 54 10\u202fPM",src:"https://github.com/user-attachments/assets/1aa8bcaa-b718-4c95-bca9-5b34059b077e"}),"\n",(0,t.jsxs)(s.ol,{start:"4",children:["\n",(0,t.jsxs)(s.li,{children:["Click on ",(0,t.jsx)(s.code,{children:"Create"}),". This creates an blank assistant."]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"1200",alt:"Screenshot 2024-11-18 at 2 55 05\u202fPM",src:"https://github.com/user-attachments/assets/1597c038-f87f-4ad0-ab81-9948368adfc5"}),"\n",(0,t.jsxs)(s.ol,{start:"6",children:["\n",(0,t.jsxs)(s.li,{children:["Define the parameters for your assistant by","\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Choosing the most relevant model from the first drop down."}),"\n",(0,t.jsx)(s.li,{children:"Provide a name to the assistant."}),"\n",(0,t.jsxs)(s.li,{children:['Provide a system prompt in the "Instructions" field. Read more on prompt engineering ',(0,t.jsx)(s.a,{href:"https://glific.org/a-simple-guide-to-using-large-language-models/",children:"here"}),"."]}),"\n",(0,t.jsx)(s.li,{children:"Set the temperature. (Temperature can be set between 0 to 2. Keeping a higher value for temperature setting increases the creativity or randomness with which the LLM generates a response. It is recommended to keep temperature at 0)"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.li,{children:"Add the files or knowledge base for the assistant to generate an answer from by uploading the files. Check here for the supported file formats by the OpenAI APIs. Click on add to complete the setup of the assistant."}),"\n"]}),"\n",(0,t.jsx)("img",{width:"698",alt:"Screenshot 2024-11-18 at 2 59 41\u202fPM",src:"https://github.com/user-attachments/assets/e45b7938-ce60-4040-90e9-685c52e75800"}),"\n",(0,t.jsxs)(s.ol,{start:"9",children:["\n",(0,t.jsxs)(s.li,{children:["The ",(0,t.jsx)(s.code,{children:"assistant id"})," provided below the assistant name is the id that needs to be copied from this page. This id will be used in the webhook nodes in the flow editor."]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"523",alt:"Screenshot 2024-11-18 at 3 15 05\u202fPM",src:"https://github.com/user-attachments/assets/02c62482-0fd8-4948-96cc-847f8e7345be"}),"\n",(0,t.jsx)(s.h2,{id:"using-the-openai-assistant-in-floweditor",children:"Using the OpenAI assistant in floweditor"}),"\n",(0,t.jsx)(s.p,{children:"Following sections details how to use assistant to answer questions from the user or create conversations."}),"\n",(0,t.jsx)(s.h3,{id:"handling-text-inputs-and-outputs",children:"Handling text inputs and outputs"}),"\n",(0,t.jsxs)(s.p,{children:["Following section shows how to use ",(0,t.jsx)(s.code,{children:"filesearch-gpt"})," webhook function in Glific flows to take users' text responses as inputs and provide a text and response."]}),"\n",(0,t.jsx)("img",{width:"867",alt:"Screenshot 2024-06-05 at 12 22 00\u202fPM",src:"https://github.com/glific/docs/assets/141305477/5021fa87-80ee-4e54-9d23-e9f17ba17358"}),"\n",(0,t.jsxs)(s.ol,{start:"0",children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:["Get the sample flow here ",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1PBcaLT3paJ8gKAeJEdLUuSPf-nxpHYKe/view?usp=sharing",children:"Sample flow\n"})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"Get the user question"}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:["In call a webhook node, select function and paste function name as ",(0,t.jsx)(s.code,{children:"filesearch-gpt"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"541",alt:"Screenshot 2024-06-05 at 12 25 17\u202fPM",src:"https://github.com/glific/docs/assets/141305477/93b24d77-84c4-4981-8ae7-15f07f0dde02"}),"\n",(0,t.jsxs)(s.ol,{start:"3",children:["\n",(0,t.jsxs)(s.li,{children:["Go to ",(0,t.jsx)(s.code,{children:"function body"})," and pass the following parameter\n",(0,t.jsx)(s.code,{children:'{   "question": "@results.flowresult",   "assistant_id": "asst_xxxxx",   "remove_citation":true }'})]}),"\n"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["in ",(0,t.jsx)(s.code,{children:"question"})," parameter pass the flow variable containing the question asked by the user"]}),"\n",(0,t.jsxs)(s.li,{children:["in ",(0,t.jsx)(s.code,{children:"assistant_id"}),' pass the assistant id obtained from Glific team in step 4 of "how to get started"']}),"\n",(0,t.jsxs)(s.li,{children:["in ",(0,t.jsx)(s.code,{children:"remove_citation"})," pass ",(0,t.jsx)(s.code,{children:"true"})," to prevent cryptic citation marks from showing up in the response."]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"624",alt:"Screenshot 2024-07-11 at 5 06 50\u202fPM",src:"https://github.com/glific/docs/assets/141305477/8ce8eb0e-5cb9-492e-a3e7-fc52260fe24b"}),"\n",(0,t.jsxs)(s.ol,{start:"4",children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"The response generated will be printed as @results.webhookresultname.message, in the given example filesearch is the webhook result name. (see the first image)"}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:["To answer the subsequent questions based on the context of the previous conversation, the subsequent webhook pass the additional parameter called ",(0,t.jsx)(s.code,{children:"thread_id"}),". This parameter has to have the value of ",(0,t.jsx)(s.code,{children:"@results.previouswebhookname.thread_id"}),'. In the example shown, the previous webhook result name is "filesearch"']}),"\n"]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"620",alt:"Screenshot 2024-07-11 at 5 07 58\u202fPM",src:"https://github.com/glific/docs/assets/141305477/40de9e15-07ec-41de-8294-64eb08d3c71e"}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.em,{children:"this is the function body passed in the subsequent webhooks to answer follow up questions"})}),"\n",(0,t.jsx)(s.h3,{id:"handling-voice-inputs-and-outputs-responses",children:"Handling voice inputs and outputs responses"}),"\n",(0,t.jsxs)(s.p,{children:["Following section shows how to use ",(0,t.jsx)(s.code,{children:"voice-filesearch-gpt"})," webhook function to take users' voice notes as inputs and provide a text and voice note output response in the desired langauge"]}),"\n",(0,t.jsx)("img",{width:"845",alt:"Screenshot 2024-08-21 at 12 05 00\u202fPM",src:"https://github.com/user-attachments/assets/ce0c771a-c15b-4017-8e7f-10675e5f367c"}),"\n",(0,t.jsxs)(s.ol,{start:"0",children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:["Get the sample flow here ",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1nOch0H5JTLSasSddeGvggP44vH9IV8Vk/view?usp=sharing",children:"Sample flow\n"})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:["In call a webhook node, select function and paste function name as ",(0,t.jsx)(s.code,{children:"voice-filesearch-gpt"})," as shown below"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"577",alt:"Screenshot 2024-08-21 at 12 05 17\u202fPM",src:"https://github.com/user-attachments/assets/320d056e-4456-4ff2-be98-895fa4b5c926"}),"\n",(0,t.jsxs)(s.ol,{start:"2",children:["\n",(0,t.jsxs)(s.li,{children:["Go to ",(0,t.jsx)(s.code,{children:"function body"})," and pass the following parameter\n",(0,t.jsx)(s.code,{children:'{   "contact": "@contact",   "speech": "@results.audio_query.input",  "assistant_id": "asst_OvmKO60CQOnHlwmnpPqqzTel",  "remove_citation": true,  "source_language": "@contact.language",  "target_language": "hindi" }'})]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"548",alt:"Screenshot 2024-08-21 at 12 21 57\u202fPM",src:"https://github.com/user-attachments/assets/d52c6ad5-7183-4bad-8572-a4b547add115"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"speech"})," is the result name which is storing the voice note sent by the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"assistant_id"})," is the assistant id created in OpenAI playground"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"source_langauge"})," is the expected language of the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"target_language"})," is the language that the response voice note needs to be in"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"remove_citation"})," pass as true to avoid citation marks to be part of the response voice note"]}),"\n"]}),"\n",(0,t.jsxs)(s.ol,{start:"4",children:["\n",(0,t.jsxs)(s.li,{children:["The text response generated will be printed as @results.webhookresultname.translated_text, in the given example ",(0,t.jsx)(s.code,{children:"gpt_voice"})," is the webhook result name."]}),"\n"]}),"\n",(0,t.jsx)("img",{width:"574",alt:"Screenshot 2024-08-21 at 12 13 49\u202fPM",src:"https://github.com/user-attachments/assets/86d81c30-f9fc-4ad5-8d32-b2248491c315"}),"\n",(0,t.jsxs)(s.ol,{start:"6",children:["\n",(0,t.jsx)(s.li,{children:"The voice note response will have to be added as an expression attachment in another send message node as @results.webhookresultname.media_url"}),"\n"]}),"\n",(0,t.jsx)("img",{width:"568",alt:"Screenshot 2024-08-21 at 12 13 39\u202fPM",src:"https://github.com/user-attachments/assets/6aa18420-a158-43ff-b631-ad9f288c2135"}),"\n",(0,t.jsx)(s.h3,{id:"pricing",children:"Pricing"}),"\n",(0,t.jsx)(s.p,{children:"NGOs can use AI featuresin Glific without any extra associated cost of inferencing. Glific is supported by OpenAI to in turn enable more NGOs to experiment, pilot and run programs using LLMs in order to further the impact without being constrained by cost."}),"\n",(0,t.jsx)(s.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsx)(s.li,{children:"The changes in the knowledge base, or the prompt have to be routed through the glific team"}),"\n",(0,t.jsx)(s.li,{children:"To get the voice notes as a response, the Glific account must have google cloud platform linked."}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"video-of-showcase",children:"Video of showcase"}),"\n",(0,t.jsx)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/J_sFgOUFFOA?si=KfDAPkoUreBudM8Z",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.em,{children:"Watch from 12 minute mark to know the exact steps to follow"})})]})}function d(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>r});var t=n(6540);const i={},o=t.createContext(i);function a(e){const s=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(o.Provider,{value:s},e.children)}}}]);